{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mB-O_VvhJXQ"
   },
   "source": [
    "# **AISaturdays ECG Challenge**\n",
    "\n",
    "![AISaturdays](https://www.saturdays.ai/assets/images/ai-saturdays-122x122.png)\n",
    "\n",
    "Bienvenidas todas las personas al reto de esta semana. Esta vez detectaremos casos de enfermedad cardiovascular a través del análisis de electrocardiogramas (ECG) de los latidos del corazón.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Se usará el lenguaje de programación Python 3.\n",
    "- Se usarán las librerías de python: Pandas, MatPlotLib, Numpy y keras.\n",
    "\n",
    "**Mediante este ejercicio, aprenderemos:**\n",
    "- Entender y ejecutar los NoteBooks con Python.\n",
    "- Ser capaz de utilizar funciones de Python y librerías adicionales.\n",
    "- Dataset:\n",
    " - Obtener el dataset y previsualizar la información del dataset.\n",
    " - Limpiar y normalizar la información del dataset.\n",
    " - Representar y analizar la información del dataset.\n",
    "- Aplicar un modelo de NN .\n",
    "- Mejorar la predicción optimizando el modelo.\n",
    "\n",
    "Este ejercicio está basado en un [paper](https://arxiv.org/pdf/1805.00794.pdf) que resuelve el problema al que nos enfrentamos. Tomadlo como una fuente de inspiración.\n",
    "\n",
    "¡Empecemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ao9twkE1hJXS"
   },
   "source": [
    "### 0. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pky60QgthJXT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1jYJBHThJXU"
   },
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mujwvIabhJXU"
   },
   "source": [
    "### 1. Importa el dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fsEI219hJXV"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZFp_wYchJXa"
   },
   "source": [
    "### 2. ¿Qué forma tiene el dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoTfVW45hJXb",
    "outputId": "8d25202a-eaef-4684-8a99-f5ee1e984019"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFsJVphghJXf"
   },
   "source": [
    "### 3. Vamos a ver cómo son los datos. Muestra las primero cinco filas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q39SynfYhJXg",
    "outputId": "1f938576-7582-4be6-b6ae-e2617585fd6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q40at1iFhJXj"
   },
   "source": [
    "Este es el dataset de hoy. Esta vez, cada columna representa una lectura del electrocardiograma (recogido a 125Hz). Si en total hay 187 lecturas, en estas columnas tenemos alrededor de segundo y medio de pulsaciones. La última columna contiene la categoría a la que pertenecen estas pulsaciones. En total hay cinco, cada una representada por un número: \n",
    "\n",
    "- Normal: 0\n",
    "- Arritmia prematura (atrial, aberrante-atrial, nodal o supra-ventricular) : 1\n",
    "- Contracción prematura ventricular o escape ventricular: 2\n",
    "- Fusión de la contracción ventricular y normal: 3\n",
    "- Resucitación, fusión de normal y resucitación o inclasificable: 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUcQbT7shJXk"
   },
   "source": [
    "### 4. Describe la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U28kFZeuhJXl",
    "outputId": "82ac2fc3-8cfc-4dcf-bb07-44dfdb4f1e2d"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2kz9b1jhJXo"
   },
   "source": [
    "### 5. Vamos a ver cómo es uno de estos electrocardiogramas. Haz una gráfica con los datos de una de las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50XGDJS5hJXp",
    "outputId": "722340f3-5829-4b6c-ec44-b3fd9a3e4b13",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGRsUDc_hJXt"
   },
   "source": [
    "### 6. Ahora que hemos visualizado nuestros datos, vamos a trabajar con ellos. Primero tenemos que dividirlos entre input y output. \n",
    "\n",
    "Divide el dataset en dos: una parte que contenga todas las columnas con datos del electrocardiograma y otro con las etiquetas. Transformar el dataset en un array de Numpy lo hace mas fácil porque puedes usar slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfVdyFcfhJXu"
   },
   "outputs": [],
   "source": [
    "#Tres lineas de código, usando .values y slicing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YloJfZUhJXw"
   },
   "source": [
    "### 7. Crea arrays con los índices de los ejemplos que pertenecen a cada categoría. La función [np.argwhere](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) viene muy bien aquí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be68Gpi2hJXx"
   },
   "outputs": [],
   "source": [
    "#5 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8DFkW8bhJX0"
   },
   "source": [
    "### 8. Cuenta cuántos ejemplos tenemos de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lvyQIIBhJX0",
    "outputId": "10274d37-df9b-4ca0-bf58-429ccff39318",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBlbXOgBhJX3"
   },
   "source": [
    "### 9. Para ver mejor cuántos tenemos de cada tipo vamos a hacer un gráfico de barras. Utiliza [plt.bar](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html) con una label apropiada para cada barra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-AMnfX0hJX3",
    "outputId": "0873d997-7f4d-407a-d3b0-9d6302b984d1"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTemtlxIhJX9"
   },
   "source": [
    "### 10. Finalmente, vamos a comparar electrocardiogramas de un tipo con los otros con otra gráfica. Dibuja un electrocardiograma de cada tipo, uno encima del otro. Puntos extra por ponerle un título y leyenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5KjUhmHhJX9"
   },
   "outputs": [],
   "source": [
    "#6 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Id6hugrmhJYA"
   },
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAgikAoWhJYB"
   },
   "source": [
    "### 11. La mejor forma de tratar con categorias es utilizar un OneHotEncoding. Transforma Y a su OneHotEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIDdzcpihJYB"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sSftNhMhJYD"
   },
   "source": [
    "### 12. Comprueba que el OneHotEncoding ha funcionado, es decir, que por cada columna en la Y original se han creado 5, y que los valores del original y el OneHotEncoding se corresponden entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xvZ_kwbhJYE",
    "outputId": "87de7a25-d38d-460b-a4be-23de53bcd09b"
   },
   "outputs": [],
   "source": [
    "#4 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OH84gOWGhJYH"
   },
   "source": [
    "### 13. Mezcla X e Y de forma aleatoria (para que las etiquetas todavía se refieran a los ejemplos originales, usa [shuffle](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AWwJCX7hJYH"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T721f2zthJYQ"
   },
   "source": [
    "### 14. Para poder introducir los datos en el modelo, necesitamos que cada punto de información esté solo dentro del array (no podemos dar un array como valor). Antes teníamos los datos estructurados así:\n",
    "\n",
    "$ X = [[a_1,a_2,a_3...,a_n],[b_1,b_2,b_3...,b_n]...[z_1,z_2,z_3,z_n] $\n",
    "\n",
    "Para poder usarlos necesitamos aislar cada uno de esos valores, sin eliminar su agrupación por ejemplos. Es decir:\n",
    "\n",
    "$ X = [[[a_1],[a_2],[a_3]...,[a_n]],[[b_1],[b_2],[b_3]...,[b_n]]...[[z_1],[z_2],[z_3],[z_n]] $\n",
    "\n",
    "Esto se consigue utilizando la función [expand_dims](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html) de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITtKUKQhhJYR"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-giOiqiYhJYT"
   },
   "source": [
    "### 15. ¡Ya casi estamos! Solo nos queda hacer un train_test_split y estaría todo listo para implementar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "js6uqn4BhJYU"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2OXup6RhJYW"
   },
   "source": [
    "## Modelos prometedores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ye1mPrYohJYW"
   },
   "source": [
    "En esta parte del challenge os planteamos un modelo ya creado para que podais ver como funciona y trastear con los diferentes parámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHGzAc55hJYX"
   },
   "source": [
    "Primero importamos unas pocas librerias para plantear el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7zqDfcAhJYX"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nC6AHHMvhJYZ"
   },
   "source": [
    "### 16. ¿Cuál es la longitud de la entrada? (Esta será la cantidad de neuronas que tendremos en la primera capa).¿Cuántas neuronas tendremos en nuestra última capa? También necesitamos un batch_size si queremos entrenar la red neuronal con SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2t48inzhJYa"
   },
   "outputs": [],
   "source": [
    "signal_length = \n",
    "n_classes = \n",
    "batch_size = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9W8F-CVJhJYd"
   },
   "source": [
    "Este es el modelo de la red neuronal. Tiene cuatro capas, dos de ellas ocultas, y utiliza como función de activación ReLU, sigmoid y softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBc_yhfThJYe",
    "outputId": "b60eb195-6c94-4a41-d75a-a00e94971fe7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=(5), input_shape=(signal_length, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdhXK-U1hJYg"
   },
   "source": [
    "Para compilar el modelo, se llama .compile(). Aquí se especifica que función de pérdida usamos, que optimizadores aplicamos y que métricas queremos guardar de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CB5NPusjhJYg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFrpp2yShJYi"
   },
   "source": [
    "Ahora entrenamos el modelo un número de épocas y con una batch_size especifica. Esto nos devuelve un objeto history con la accuracy de todas las fases de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mf7fDdchJYi",
    "outputId": "6656fc56-133a-4a48-bd49-77efaa251f63"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=75, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NliUnXSGhJYl"
   },
   "source": [
    "### 17. Accede a la accuracy histórica del modelo (con el atributo history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWds4b6ChJYl",
    "outputId": "a4255044-3b63-4b4d-adea-08a65c5da792"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzB3t9CYhJYo"
   },
   "source": [
    "### 18. Ahora podemos ver si nuestro modelo está haciendo overfitting. Dibuja una gráfica con la accuracy en train y en validation usando los datos del objeto history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KP_SRAnphJYp",
    "outputId": "43c5e9ba-51c1-4adc-aaa2-fe1e4825d40b"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2RC2_pghJYr"
   },
   "source": [
    "### 19. Lo mismo, pero con la pérdida o loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaJxqJWYhJYs",
    "outputId": "b320b106-1c86-4e5b-d9d4-a6f186e54b4b"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFu3wMNZhJYv"
   },
   "source": [
    "### 20. Vamos a ver lo que predice con el X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vd1FIayQhJYw"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVhxvfzLhJYy"
   },
   "source": [
    "### 21. ¿Qué dimensiones tiene la predicción y_pred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M4DrqzZhJYz",
    "outputId": "4fd63c75-7e76-4c07-e2be-29f6f5217ad6"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBuCsReShJY2"
   },
   "source": [
    "### 22. Compara una predicción con el valor esperado utilizando un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGsxbYnWhJY3",
    "outputId": "61943267-f1d2-42c8-d9e3-2a57ee8de15e"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXFer3AZhJY5"
   },
   "source": [
    "¿El modelo plantea una sola posibilidad o las probabilidades de cada categoria al estimar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoQVwwFhhJY5"
   },
   "source": [
    "Este snippet de código genera un report del modelo, y el siguiente una matriz de confusión. Utilizadlo para evaluar vuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YX_k97bghJY6",
    "outputId": "53a2a5b0-49c7-4c98-c3e3-b1e5f225de73"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3E_a95ihJY8",
    "outputId": "77424721-254d-4556-a7b0-fa7f40a16bf9"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n",
    "                      title='Confusion matrix, with normalization',\n",
    "                      normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXtlz07VhJZB"
   },
   "source": [
    "**Preguntas:**\n",
    "- Si tomamos todo lo que no sea normal como positivo, ¿el modelo se equivoca mas en falsos positivos o en falsos negativos?\n",
    "- ¿Que categoría genera mayor error?\n",
    "- ¿Existe overfitting?\n",
    "- ¿Como afecta batch_size al entrenamiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jdUQrynhJZD"
   },
   "source": [
    "Ahora os toca a vosotros mejorar el modelo. Probad con otros optimizadores, cambiar la función de coste, volveros locos con el batch_size..... El paper del principio puede dar alguna pista. Como siempre, el que tenga la mejor score, ¡tiene premio!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AISaturdays_ChallengeSession5.ipynb",
   "provenance": [
    {
     "file_id": "1eDULJv1udQFKK4WLY0M_f9jBxibhzmXs",
     "timestamp": 1583527306059
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
