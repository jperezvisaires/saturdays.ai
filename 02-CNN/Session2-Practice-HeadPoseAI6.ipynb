{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ziY8dujBRHWh"
   },
   "source": [
    "# Practice: Head Pose Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Hola! Vamos de lleno con la Practice de esta semana. \n",
    "\n",
    "El objetivo es detectar dónde está mirando una persona fijándose en una foto de su cara.\n",
    "\n",
    "Para ello, utilizaremos el Dataset que se puede encontrar en http://crowley-coutaz.fr/HeadPoseDataSet/HeadPoseImageDatabase.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tb6ScVgeRVYP"
   },
   "source": [
    "### 0. Importación de librerías\n",
    "\n",
    "Como siempre, recuerda importar las librerías que vayas a necesitar. Te hemos dejado las que podrían serte necesarias para este caso.\n",
    "\n",
    "Es importante que si no sabes para qué puede valer una librería, hagas una búsqueda y entiendas por qué ha sido importada. Es bastante probable que así puedas identificar mejor las que deberás usar en los siguientes pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7P6fXXGQ-ZE"
   },
   "outputs": [],
   "source": [
    "#--------------------Librerias--------------------\n",
    "\n",
    "# os dejamos las básicas, añadid las que convengan\n",
    "\n",
    "import cv2  # OpenCV 2 for capturing frames from the video\n",
    "import os  # For managing paths and directories in the project\n",
    "import shutil  # High level file operations\n",
    "import numpy as np  # Arrays\n",
    "import keras  # High level NN API\n",
    "from PIL import Image, ImageOps # For image processing\n",
    "from pathlib import Path  # For easily managing paths\n",
    "from IPython import display  # For displaying images inline with the notebook\n",
    "from sklearn.model_selection import train_test_split  # For train-test splitting\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1p6FzVwLSRXp"
   },
   "source": [
    "### 1. Descarga de Dataset: Head Pose Image Database (Gourier, Hall, & Crowley, 2004)\n",
    "\n",
    "Lo siguiente es descargar el dataset de http://crowley-coutaz.fr/HeadPoseDataSet/HeadPoseImageDatabase.tar.gz y estructurar los datos para dejarlos listos para su uso (descompresión del archivo tar.gz, creación de variables, tratamiento de expresiones regulares ...).\n",
    "\n",
    "La información relevante a la construcción del dataset se puede encontrar en http://crowley-coutaz.fr/Head%20Pose%20Image%20Database.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Descarga y tratamiento como archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuGnmq8-SpYs"
   },
   "outputs": [],
   "source": [
    "url = 'http://crowley-coutaz.fr/HeadPoseDataSet/HeadPoseImageDatabase.tar.gz'\n",
    "name = 'HeadPoseImageDatabase.tar.gz'\n",
    "\n",
    "#Insertar a continuación uso de librería requests \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Descomprime del archivo tar.gz, usando el Linux que hay debajo de Jupyter Notebook, mediante el comando tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato del archivo:\n",
    "\n",
    "Recordad que en el enlace de información se describe cómo está guardada la información, estando en cada archivo de la imagen los ángulos de inclinación y giro (tilt,pan) y las coordenadas de la cara (x,y), altura y anchura (h,w) dentro del archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Tratamiento de las expresiones regulares de los títulos de las imágenes para conseguir las caracteristicas\n",
    "\n",
    "Os dejamos esta función para que, dado el path de una imagen, pueda transformarla a un tamaño más trabajable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_df(image_path, shape):\n",
    "    image = Image.open(image_path)\n",
    "    image_resized = image.resize(shape, Image.ANTIALIAS)\n",
    "    img_array = np.asarray(image_resized)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos en el dataframe, extraidos de cada archivo (nombre del archivo y contenidos)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Finalmente deberíais tener algo como lo siguiente\n",
    "\n",
    "df.columns = [\"X\", \"Y\", \"H\", \"W\", \"T\", \"P\", \"Image\"]\n",
    "df.X = df.X.astype(int)\n",
    "df.Y = df.Y.astype(int)\n",
    "df.H = df.H.astype(int)\n",
    "df.W = df.W.astype(int)\n",
    "df = df.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Separado en X (datos) e Y (a predecir) y su normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(list(df[\"Image\"]/255.))\n",
    "Y = np.array(df[[\"X\", \"Y\", \"H\", \"W\", \"T\", \"P\"]])/100.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 Split de conjuntos finales de x_train, y_train, x_test y y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9f_4xdWAStJU"
   },
   "source": [
    "### 2 Importado de red neuronal MobileNet sin incluir la última capa\n",
    "\n",
    "El objetivo aquí es importar la red neuronal MobileNet (una arquitectura que ha demostrado ser bastante eficiente para este problema) excluyendo la última capa. Con ello, descartaremos la última capa, para posteriormente crearla nosotros y concatenar las dos partes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Importar la red de Keras sin la última capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqvp4P2nUHGU"
   },
   "outputs": [],
   "source": [
    "# Nosotros como hemos dicho os recomendamos Mobilenet\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "n_classes = 6\n",
    "base_model = MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Crear nuestra última capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Juntar la red y la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añade el código que falta para unir la red y la capa nueva generada.\n",
    "\n",
    "model=\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Compilar (elegir optimizador, funcion de perdida(loss) y métrica de error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = '',\n",
    "              loss ='',\n",
    "              metrics = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwHKpaHlUZTd"
   },
   "source": [
    "##### 2.5 Entrenar la red que hemos importado y manipulado con el dataset que hemos tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2aSH22geUt2e"
   },
   "outputs": [],
   "source": [
    "#--------------------Entrenamiento de nuestra red personalizada--------------------\n",
    "# Un precioso fit() y a esperar. Unas 10 épocas deberian dar un resultado decente\n",
    "model.fit(X_train, Y_train, validation_data=[X_test, Y_test], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Vwyi4bLUyZn"
   },
   "source": [
    "##### 2.6 Visualizar un diagrama de correlación entre los valores predichos y los valores que debieran ser (usando por ejemplo el RMSE o R2 dado por sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiWhF4VIVIF5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PlantillaHeadPoseAI6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
